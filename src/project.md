---
title: Political Polarization and Online Influence Operations
subtitle: PIs -- Michael Bossetta, Nils Holmberg
co-applicants: humlab, psych, industry, etc
---

# Intro, background

Aims, objectives, purpose. How are online influence operations (social media, hyperpartisan online news, disinfo websites, conspiracy videos, antivax) constructed, and what polarizing effects do they have on users?

online influence operations (IOs) can be modelled on the example of digital marketing campaigns, but with the difference that political interests are the ultimate goal rather than commercial.

the research on online IOs have developed sophisticated methods for analyzing online content and social networks. however research on media effects on target audiences remains understudied

research on effective countermeasures to online influence operations is also scarce.. to some extent because media effects are difficult to study (time, confounding factors, individual differences)

Media and communication psychology framework: media effects, personality traits, content features. 

## Polarization on individual level

Physiological correlates of affective polarization. Emotional image stimuli (<http://wang.ist.psu.edu/emotion/kim2017.htm>), combine with text to generate political advert stimuli. Do individuals with certain personality traits (high neuroticism, emotionality) have a higher susceptibility to polarization, higher risks of negative effects?

## Polarization on social level

Role of ethnicity in spread of disinfo, online influence operations

## Ethics and legal

Approval from ethical review board necessary for processing facial images in machine learning applications (e.g. deepfake generation), and when eleciting cognitive effects (e.g. memory effects). Manipulation of elections, ICCPR article 27-31

platforms provide data for vetting researchers?

algoritmer, en ko-ordinator myndighet står för vetting inom varje land (post- och telestyrelsen)

hur kan detta samarbete se ut mellan platform och universitet?

## Research technology

AIML in swedish language context, web portal with language models, collaboration with lund humanities lab

Moderation robots

communication

# Litterature review

Concepts, theories: Differential, conditional media effects (Valkenburg). Connecting online content features and user behavioral/cognitive/emotional effects. Communication effects (lack of). Web interfaces. Profile source cue verification. "Previous research, research gaps"

# Methods, Empirical studies

External collaborations: Partnership for Countering Influence Operations, Carnegie Endowment for International Peace, FB, Tobii, EUvsDisinfo? HUMLAB. Collaboration with psy.lu.se (Axel Ekström, Mikael Johansson)

## Study 1

### Aims and purpose  

Timeline. RQ, hypotheses, methods. Web scraping and automated content analysis (AIML). Social network analysis to identify inauthentic content, activity. Port methods for computational content analysis to Swedish language context. Comparative swedish-english component. Use GPT-3 approach to generate text messages, use as stimuli to study effects on human users.

### Existing research and hypotheses 

### Design and data 

### Contributions and significance

## Study 2

### Aims and purpose  

### Existing research and hypotheses 

### Design and data 

### Contributions and significance

Timeline. RQ, hypotheses, methods. Psychological and physiological experiments, physiological correlates of affective polarization, pupil dilation, GSR, EEG, fMRI etc. Web browsing behavior.

Memory of polarization exposure during distraction task. Benefit: only one experiment session.

## Study 3

Timeline. RQ, hypotheses, methods. Moral machines. Road blockage, no time to brake. Choose casualties. Automatized counter-measures to disinformation campaigns.

## Study 4

Timeline. RQ, hypotheses, methods. Antivax movement, polarization around covid-19 vaccinations. Online influence operations. the climate, sustainability angle could easily fit into the disinfo campaign research area.. the core idea would be to survey participants issue involvement (maybe as a pretest) and present normal vs deepfake videos of politicians that either support or go against their beliefs.. the hypothesis would be that deepfakes as such induce higher levels of fear (michael), higher levels of recall (axel), and lower levels of attitudes to politician (nils)

# Expected results, contribution

individual level

group level

ethics and legal

technology, methods

communication

collaborations with FB, twitter, Swedish Institute (countering disinfo campaigns)

- **RQ:** How are online influence operations (social media, websites, video etc) constructed, and what polarizing effects do they have on users?

- **Concepts, theories:** Differential, conditional media effects (Valkenburg). Connecting online content features and user behavioral/cognitive/emotional effects. Communication effects (lack of). Web interfaces. Profile source cue verification.

- **Methodology:** Web scraping and automated content analysis (AIML). Social network analysis to identify inauthentic content, activity. Psychological and physiological experiments, physiological correlates of affective polarization, pupil dilation, GSR, EEG, fMRI etc

- **Material, Data:** Twitter data, Facebook pages API data, Online news websites, video data, web interaction data (web measures, likes), physiological data. Anything relating to Swedish election 2022?

- Pi:s/coordin: check the mindmap!

- **External collaborations:** Partnership for Countering Influence Operations, Carnegie Endowment for International Peace, FB, Tobii, EUvsDisinfo? HUMLAB. The Swedish Civil Contingencies Agency (MSB)

- Individual vertical, continue to group level

- Personality traits, big five => divide into 1) content, 2) effects

- International comparisons?




